{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ee6587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to open the video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " \n",
    "\n",
    "pedestrian_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_fullbody.xml')\n",
    "\n",
    " \n",
    "\n",
    "video_path='VIDEO.mp4'\n",
    "\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "\n",
    " \n",
    "\n",
    "if not cap.isOpened():\n",
    "\n",
    "    print(\"Error: Unable to open the video\")\n",
    "\n",
    "    exit()\n",
    "\n",
    "   \n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "\n",
    "        break\n",
    "\n",
    "   \n",
    "\n",
    "    gray_frame=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "   \n",
    "\n",
    "    pedestrians=pedestrian_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))\n",
    "\n",
    "   \n",
    "\n",
    "    for (x,y,w,h) in pedestrians:\n",
    "\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "   \n",
    "\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    " \n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dfa4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to open the video.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 # run in idle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation # Initialize the Haar Cascade pedestrian detection model\n",
    "pedestrian_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml') \n",
    "# Load the video \n",
    "video_path = 'traffic.mp4' \n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully if not cap.isOpened(): \n",
    "print(\"Error: Unable to open the video.\") \n",
    "exit() # Enable inline plots with static backend %matplotlib inline # Function to detect pedestrians and draw bounding boxes\n",
    "\n",
    "def detect_pedestrians(frame): # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Detect pedestrians in the grayscale frame\n",
    "    pedestrians = pedestrian_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) \n",
    "    # Draw rectangles around the detected pedestrians for (x, y, w, h) in pedestrians:\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "# Function to update the animation\n",
    "def update(frame): # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: ani.event_source.stop() \n",
    "    return \n",
    "    # Detect pedestrians and draw bounding boxes\n",
    "    frame_with_pedestrians = detect_pedestrians(frame) # Display the frame\n",
    "    img.set_data(cv2.cvtColor(frame_with_pedestrians, cv2.COLOR_BGR2RGB)) \n",
    "    return img,\n",
    "\n",
    "# Create the animation \n",
    "fig = plt.figure()\n",
    "plt.axis('off') # Turn off axis labels\n",
    "ani = animation.FuncAnimation(fig, update, interval=50, cache_frame_data=False) # Display the animation \n",
    "plt.show() # Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085dcd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
